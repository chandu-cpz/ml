{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Inter op parallelism cannot be modified after initialization.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/chandu/git/ml/Notes-ipynb/DL/ANN_Regression.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/chandu/git/ml/Notes-ipynb/DL/ANN_Regression.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/chandu/git/ml/Notes-ipynb/DL/ANN_Regression.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(tf\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mthreading\u001b[39m.\u001b[39;49mset_inter_op_parallelism_threads(\u001b[39m8\u001b[39;49m))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/framework/config.py:144\u001b[0m, in \u001b[0;36mset_inter_op_parallelism_threads\u001b[0;34m(num_threads)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mconfig.threading.set_inter_op_parallelism_threads\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_inter_op_parallelism_threads\u001b[39m(num_threads):\n\u001b[1;32m    136\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Set number of threads used for parallelism between independent operations.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \n\u001b[1;32m    138\u001b[0m \u001b[39m  Determines the number of threads used by independent non-blocking operations.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m    num_threads: Number of parallel threads\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m   context\u001b[39m.\u001b[39;49mcontext()\u001b[39m.\u001b[39;49minter_op_parallelism_threads \u001b[39m=\u001b[39m num_threads\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1962\u001b[0m, in \u001b[0;36mContext.inter_op_parallelism_threads\u001b[0;34m(self, num_threads)\u001b[0m\n\u001b[1;32m   1959\u001b[0m   \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1961\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context_handle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1962\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1963\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mInter op parallelism cannot be modified after initialization.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1965\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inter_op_parallelism_threads \u001b[39m=\u001b[39m num_threads\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Inter op parallelism cannot be modified after initialization."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.config.threading.set_inter_op_parallelism_threads(8)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/50_Startups.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R&D Spend          0\n",
       "Administration     0\n",
       "Marketing Spend    0\n",
       "State              0\n",
       "Profit             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/usr/lib/python3/dist-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df.State = le.fit_transform(df.State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1].values\n",
    "y = df.Profit.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(Dense(4,activation = 'relu'))\n",
    "regressor.add(Dense(12,activation = 'relu'))\n",
    "regressor.add(Dense(8, activation= 'relu'))\n",
    "regressor.add(Dense(9, activation= 'relu'))\n",
    "regressor.add(Dense(1, activation= 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer= 'adam', loss= 'mse', metrics= ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 16ms/step - loss: 14390565888.0000 - mse: 14390565888.0000\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 14226283520.0000 - mse: 14226283520.0000\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 14077960192.0000 - mse: 14077959168.0000\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 13967517696.0000 - mse: 13967517696.0000\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 13922494464.0000 - mse: 13922494464.0000\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 13884265472.0000 - mse: 13884263424.0000\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 13857312768.0000 - mse: 13857312768.0000\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 13831748608.0000 - mse: 13831748608.0000\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 13809808384.0000 - mse: 13809808384.0000\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 13790627840.0000 - mse: 13790627840.0000\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13772992512.0000 - mse: 13772992512.0000\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 13754651648.0000 - mse: 13754651648.0000\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13738046464.0000 - mse: 13738046464.0000\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 13718525952.0000 - mse: 13718525952.0000\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13697729536.0000 - mse: 13697729536.0000\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 13672526848.0000 - mse: 13672526848.0000\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13642650624.0000 - mse: 13642650624.0000\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13605345280.0000 - mse: 13605345280.0000\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13553396736.0000 - mse: 13553396736.0000\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13482085376.0000 - mse: 13482085376.0000\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13393063936.0000 - mse: 13393063936.0000\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 13250896896.0000 - mse: 13250896896.0000\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 13046046720.0000 - mse: 13046045696.0000\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 12780893184.0000 - mse: 12780893184.0000\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12346901504.0000 - mse: 12346901504.0000\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11773689856.0000 - mse: 11773689856.0000\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10975356928.0000 - mse: 10975356928.0000\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9908999168.0000 - mse: 9908999168.0000\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8709757952.0000 - mse: 8709757952.0000\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7251945472.0000 - mse: 7251945472.0000\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5602102272.0000 - mse: 5602102272.0000\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 4104580352.0000 - mse: 4104580352.0000\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2801461504.0000 - mse: 2801461504.0000\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1858765056.0000 - mse: 1858765056.0000\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1385143936.0000 - mse: 1385143936.0000\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1238381312.0000 - mse: 1238381312.0000\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1225818112.0000 - mse: 1225818112.0000\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1211444608.0000 - mse: 1211444608.0000\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1181060992.0000 - mse: 1181060992.0000\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1156501632.0000 - mse: 1156501632.0000\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1137667456.0000 - mse: 1137667456.0000\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1120196608.0000 - mse: 1120196608.0000\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1101554048.0000 - mse: 1101554048.0000\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 1089011200.0000 - mse: 1089011200.0000\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1071935296.0000 - mse: 1071935296.0000\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1056822720.0000 - mse: 1056822720.0000\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1048839680.0000 - mse: 1048839680.0000\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 1025491072.0000 - mse: 1025491072.0000\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1013283200.0000 - mse: 1013283200.0000\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 1001870336.0000 - mse: 1001870336.0000\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 990866176.0000 - mse: 990866304.0000\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 975266432.0000 - mse: 975266368.0000\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 965231680.0000 - mse: 965231680.0000\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 949816768.0000 - mse: 949816768.0000\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 938346432.0000 - mse: 938346432.0000\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 926912320.0000 - mse: 926912320.0000\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 913568000.0000 - mse: 913568000.0000\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 902989056.0000 - mse: 902989056.0000\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 892623232.0000 - mse: 892623168.0000\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 878787328.0000 - mse: 878787328.0000\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 869564672.0000 - mse: 869564672.0000\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 860725312.0000 - mse: 860725312.0000\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 849207744.0000 - mse: 849207744.0000\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 839141888.0000 - mse: 839141888.0000\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 829132544.0000 - mse: 829132544.0000\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 818713216.0000 - mse: 818713216.0000\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 808569216.0000 - mse: 808569216.0000\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 800128896.0000 - mse: 800128896.0000\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 787451200.0000 - mse: 787451200.0000\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 775730688.0000 - mse: 775730688.0000\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 767754560.0000 - mse: 767754560.0000\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 761220800.0000 - mse: 761220800.0000\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 748354944.0000 - mse: 748354944.0000\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 742148736.0000 - mse: 742148736.0000\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 731728064.0000 - mse: 731728064.0000\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 720886208.0000 - mse: 720886208.0000\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 712037312.0000 - mse: 712037312.0000\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 705894464.0000 - mse: 705894464.0000\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 697017920.0000 - mse: 697017920.0000\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 688057792.0000 - mse: 688057792.0000\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679694528.0000 - mse: 679694528.0000\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 670766336.0000 - mse: 670766336.0000\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 664357632.0000 - mse: 664357632.0000\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 659125312.0000 - mse: 659125312.0000\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 647854464.0000 - mse: 647854464.0000\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 640560576.0000 - mse: 640560576.0000\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 633344832.0000 - mse: 633344832.0000\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 627959872.0000 - mse: 627959936.0000\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 621475200.0000 - mse: 621475200.0000\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 612490304.0000 - mse: 612490304.0000\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 605266752.0000 - mse: 605266752.0000\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 597512128.0000 - mse: 597512128.0000\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 592895936.0000 - mse: 592895936.0000\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 586328192.0000 - mse: 586328192.0000\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 578127296.0000 - mse: 578127296.0000\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 572218048.0000 - mse: 572218048.0000\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 565371328.0000 - mse: 565371328.0000\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 559256960.0000 - mse: 559256960.0000\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 553515776.0000 - mse: 553515776.0000\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 547946688.0000 - mse: 547946688.0000\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 540440768.0000 - mse: 540440768.0000\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 536330464.0000 - mse: 536330464.0000\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 531593312.0000 - mse: 531593312.0000\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 525217024.0000 - mse: 525217024.0000\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 517359648.0000 - mse: 517359648.0000\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 513862432.0000 - mse: 513862432.0000\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 510267232.0000 - mse: 510267232.0000\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 501713408.0000 - mse: 501713408.0000\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 496456544.0000 - mse: 496456544.0000\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 491484288.0000 - mse: 491484288.0000\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 485360768.0000 - mse: 485360768.0000\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 481558144.0000 - mse: 481558144.0000\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 478495712.0000 - mse: 478495712.0000\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 470714560.0000 - mse: 470714624.0000\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 464424128.0000 - mse: 464424096.0000\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 460114336.0000 - mse: 460114336.0000\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 456723776.0000 - mse: 456723808.0000\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 450603840.0000 - mse: 450603840.0000\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 445415904.0000 - mse: 445415904.0000\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 440690848.0000 - mse: 440690848.0000\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 435601152.0000 - mse: 435601152.0000\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 431828384.0000 - mse: 431828384.0000\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 428081504.0000 - mse: 428081504.0000\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 422975616.0000 - mse: 422975616.0000\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 419741440.0000 - mse: 419741440.0000\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 415074464.0000 - mse: 415074464.0000\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 410907168.0000 - mse: 410907168.0000\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 411109280.0000 - mse: 411109280.0000\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 403794112.0000 - mse: 403794112.0000\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 397771744.0000 - mse: 397771744.0000\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 395274144.0000 - mse: 395274176.0000\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 390878272.0000 - mse: 390878272.0000\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 386975104.0000 - mse: 386975104.0000\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 386032672.0000 - mse: 386032640.0000\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 379737280.0000 - mse: 379737280.0000\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 375593536.0000 - mse: 375593536.0000\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 371588288.0000 - mse: 371588320.0000\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 367999712.0000 - mse: 367999712.0000\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 367612928.0000 - mse: 367612928.0000\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 360586784.0000 - mse: 360586784.0000\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 358346112.0000 - mse: 358346112.0000\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 354959360.0000 - mse: 354959360.0000\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 351893440.0000 - mse: 351893440.0000\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 347519328.0000 - mse: 347519328.0000\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 345278944.0000 - mse: 345278944.0000\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 341386688.0000 - mse: 341386688.0000\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 339096864.0000 - mse: 339096864.0000\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 335242112.0000 - mse: 335242112.0000\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 332184384.0000 - mse: 332184384.0000\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 329746720.0000 - mse: 329746720.0000\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332648032.0000 - mse: 332648032.0000\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 323282784.0000 - mse: 323282784.0000\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 326253024.0000 - mse: 326253024.0000\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 320471968.0000 - mse: 320471968.0000\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 316056128.0000 - mse: 316056128.0000\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 317363360.0000 - mse: 317363360.0000\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 312153600.0000 - mse: 312153600.0000\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 307688128.0000 - mse: 307688128.0000\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 305820896.0000 - mse: 305820896.0000\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 302551552.0000 - mse: 302551552.0000\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 300997216.0000 - mse: 300997216.0000\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 297278016.0000 - mse: 297278016.0000\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 296555712.0000 - mse: 296555712.0000\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 294710880.0000 - mse: 294710848.0000\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 290406240.0000 - mse: 290406240.0000\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 288381856.0000 - mse: 288381856.0000\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 286640544.0000 - mse: 286640544.0000\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 283359648.0000 - mse: 283359648.0000\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 282180416.0000 - mse: 282180416.0000\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 278351552.0000 - mse: 278351552.0000\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 277540480.0000 - mse: 277540480.0000\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 275616384.0000 - mse: 275616384.0000\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 272867424.0000 - mse: 272867424.0000\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 270593344.0000 - mse: 270593344.0000\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 269578752.0000 - mse: 269578752.0000\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 267500368.0000 - mse: 267500368.0000\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 265372384.0000 - mse: 265372384.0000\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 264064480.0000 - mse: 264064480.0000\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 261784160.0000 - mse: 261784160.0000\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 259809632.0000 - mse: 259809632.0000\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 258206048.0000 - mse: 258206048.0000\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 256903200.0000 - mse: 256903200.0000\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 255450048.0000 - mse: 255450048.0000\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 253360320.0000 - mse: 253360320.0000\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 252020784.0000 - mse: 252020784.0000\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 251218544.0000 - mse: 251218544.0000\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 248717664.0000 - mse: 248717664.0000\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 248417888.0000 - mse: 248417888.0000\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 246115008.0000 - mse: 246115008.0000\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 244570576.0000 - mse: 244570576.0000\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 244289424.0000 - mse: 244289424.0000\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 241690576.0000 - mse: 241690576.0000\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 240076416.0000 - mse: 240076416.0000\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 238151680.0000 - mse: 238151680.0000\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 237650880.0000 - mse: 237650880.0000\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 239294896.0000 - mse: 239294896.0000\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 235520656.0000 - mse: 235520656.0000\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 233712960.0000 - mse: 233712928.0000\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 233851072.0000 - mse: 233851072.0000\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 231773792.0000 - mse: 231773792.0000\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 232369200.0000 - mse: 232369200.0000\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 229274096.0000 - mse: 229274096.0000\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 228615648.0000 - mse: 228615648.0000\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 227478672.0000 - mse: 227478672.0000\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 226420080.0000 - mse: 226420080.0000\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 225306272.0000 - mse: 225306272.0000\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 226962208.0000 - mse: 226962208.0000\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 224209776.0000 - mse: 224209776.0000\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 222383056.0000 - mse: 222383056.0000\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 221194336.0000 - mse: 221194336.0000\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 222571040.0000 - mse: 222571040.0000\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 221842384.0000 - mse: 221842384.0000\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 219657024.0000 - mse: 219657040.0000\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 218328576.0000 - mse: 218328576.0000\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 217997392.0000 - mse: 217997392.0000\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 217350784.0000 - mse: 217350768.0000\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 216436720.0000 - mse: 216436720.0000\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 215517360.0000 - mse: 215517360.0000\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 215083200.0000 - mse: 215083216.0000\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 214339600.0000 - mse: 214339600.0000\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 213718384.0000 - mse: 213718384.0000\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 213199312.0000 - mse: 213199312.0000\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 214210864.0000 - mse: 214210864.0000\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 212463312.0000 - mse: 212463312.0000\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 211181984.0000 - mse: 211181984.0000\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 210828576.0000 - mse: 210828576.0000\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 210951648.0000 - mse: 210951648.0000\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 210794544.0000 - mse: 210794544.0000\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 209208832.0000 - mse: 209208832.0000\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 209509856.0000 - mse: 209509856.0000\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 208742272.0000 - mse: 208742272.0000\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 209749680.0000 - mse: 209749680.0000\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 208472208.0000 - mse: 208472208.0000\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 208113824.0000 - mse: 208113824.0000\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 206628352.0000 - mse: 206628352.0000\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 209156864.0000 - mse: 209156864.0000\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 206590848.0000 - mse: 206590848.0000\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 206242736.0000 - mse: 206242736.0000\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 206664416.0000 - mse: 206664416.0000\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 205344672.0000 - mse: 205344672.0000\n",
      "Epoch 241/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 206024288.0000 - mse: 206024288.0000\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 206503136.0000 - mse: 206503136.0000\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 203545120.0000 - mse: 203545120.0000\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 203960080.0000 - mse: 203960080.0000\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 203409904.0000 - mse: 203409904.0000\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 202991616.0000 - mse: 202991616.0000\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 204038752.0000 - mse: 204038752.0000\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 202301744.0000 - mse: 202301744.0000\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 202889856.0000 - mse: 202889856.0000\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 202150208.0000 - mse: 202150208.0000\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 204291408.0000 - mse: 204291392.0000\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 203581712.0000 - mse: 203581712.0000\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 203477312.0000 - mse: 203477312.0000\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 201642272.0000 - mse: 201642272.0000\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 203172112.0000 - mse: 203172112.0000\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 201855264.0000 - mse: 201855264.0000\n",
      "Epoch 257/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 200862784.0000 - mse: 200862784.0000\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 202092000.0000 - mse: 202092000.0000\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 200211200.0000 - mse: 200211200.0000\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 201823824.0000 - mse: 201823824.0000\n",
      "Epoch 261/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 201587280.0000 - mse: 201587280.0000\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 206370096.0000 - mse: 206370096.0000\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 200546640.0000 - mse: 200546640.0000\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 200248544.0000 - mse: 200248544.0000\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 200212992.0000 - mse: 200212992.0000\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 200837392.0000 - mse: 200837392.0000\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 199970640.0000 - mse: 199970640.0000\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 199422336.0000 - mse: 199422336.0000\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 199696560.0000 - mse: 199696560.0000\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 199482608.0000 - mse: 199482608.0000\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 198703328.0000 - mse: 198703328.0000\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 200398304.0000 - mse: 200398304.0000\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 200143168.0000 - mse: 200143168.0000\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 199170496.0000 - mse: 199170512.0000\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 198844688.0000 - mse: 198844688.0000\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 199160976.0000 - mse: 199160976.0000\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 200433344.0000 - mse: 200433344.0000\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 198926720.0000 - mse: 198926720.0000\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 198622528.0000 - mse: 198622528.0000\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 199135248.0000 - mse: 199135248.0000\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 198963056.0000 - mse: 198963056.0000\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 198381264.0000 - mse: 198381264.0000\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 198686832.0000 - mse: 198686832.0000\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 197980672.0000 - mse: 197980672.0000\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 198098784.0000 - mse: 198098784.0000\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 198139568.0000 - mse: 198139568.0000\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 198406608.0000 - mse: 198406608.0000\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 197926384.0000 - mse: 197926384.0000\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 199444016.0000 - mse: 199444032.0000\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 199810384.0000 - mse: 199810384.0000\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 198148768.0000 - mse: 198148768.0000\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 197945984.0000 - mse: 197945984.0000\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 198329520.0000 - mse: 198329536.0000\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 197202384.0000 - mse: 197202384.0000\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 197830192.0000 - mse: 197830192.0000\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 199028880.0000 - mse: 199028880.0000\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 197764800.0000 - mse: 197764800.0000\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 197757856.0000 - mse: 197757824.0000\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 197977600.0000 - mse: 197977600.0000\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 198274960.0000 - mse: 198274960.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fa03928a9d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(x_train, y_train, batch_size= 10, epochs= 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8839610202074326"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 41268.773, 127343.95 ,  82099.414, 177383.11 ,  97774.01 ,\n",
       "       122685.93 , 129158.94 , 167558.2  , 119296.836,  44079.062,\n",
       "       104165.234, 121368.34 ,  41268.773, 133911.05 ,  66980.59 ,\n",
       "       131601.33 , 131601.33 , 104657.89 ,  71272.84 , 143029.19 ,\n",
       "       157007.88 , 160917.45 , 110540.95 , 162256.61 ,  93180.53 ,\n",
       "       174480.31 , 127290.26 ,  17195.531,  87890.64 , 149297.58 ,\n",
       "        71295.85 , 203775.38 , 203631.56 ], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Profit</th>\n",
       "      <th>Predicted Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64926.08</td>\n",
       "      <td>41268.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146121.95</td>\n",
       "      <td>127343.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90708.19</td>\n",
       "      <td>82099.414062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>191050.39</td>\n",
       "      <td>177383.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108552.04</td>\n",
       "      <td>97774.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144259.40</td>\n",
       "      <td>122685.929688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>124266.90</td>\n",
       "      <td>129158.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>155752.60</td>\n",
       "      <td>167558.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>126992.93</td>\n",
       "      <td>119296.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42559.73</td>\n",
       "      <td>44079.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101004.64</td>\n",
       "      <td>104165.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>110352.25</td>\n",
       "      <td>121368.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64926.08</td>\n",
       "      <td>41268.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>111313.02</td>\n",
       "      <td>133911.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>89949.14</td>\n",
       "      <td>66980.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>134307.35</td>\n",
       "      <td>131601.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>134307.35</td>\n",
       "      <td>131601.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>96712.80</td>\n",
       "      <td>104657.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>49490.75</td>\n",
       "      <td>71272.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>129917.04</td>\n",
       "      <td>143029.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>132602.65</td>\n",
       "      <td>157007.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>152211.77</td>\n",
       "      <td>160917.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>105733.54</td>\n",
       "      <td>110540.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>166187.94</td>\n",
       "      <td>162256.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>96778.92</td>\n",
       "      <td>93180.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>182901.99</td>\n",
       "      <td>174480.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>105008.31</td>\n",
       "      <td>127290.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>35673.41</td>\n",
       "      <td>17195.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>99937.59</td>\n",
       "      <td>87890.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>156122.51</td>\n",
       "      <td>149297.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>81005.76</td>\n",
       "      <td>71295.851562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>192261.83</td>\n",
       "      <td>203775.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>191792.06</td>\n",
       "      <td>203631.562500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual Profit  Predicted Profit\n",
       "0        64926.08      41268.773438\n",
       "1       146121.95     127343.953125\n",
       "2        90708.19      82099.414062\n",
       "3       191050.39     177383.109375\n",
       "4       108552.04      97774.007812\n",
       "5       144259.40     122685.929688\n",
       "6       124266.90     129158.937500\n",
       "7       155752.60     167558.203125\n",
       "8       126992.93     119296.835938\n",
       "9        42559.73      44079.062500\n",
       "10      101004.64     104165.234375\n",
       "11      110352.25     121368.343750\n",
       "12       64926.08      41268.773438\n",
       "13      111313.02     133911.046875\n",
       "14       89949.14      66980.593750\n",
       "15      134307.35     131601.328125\n",
       "16      134307.35     131601.328125\n",
       "17       96712.80     104657.890625\n",
       "18       49490.75      71272.843750\n",
       "19      129917.04     143029.187500\n",
       "20      132602.65     157007.875000\n",
       "21      152211.77     160917.453125\n",
       "22      105733.54     110540.953125\n",
       "23      166187.94     162256.609375\n",
       "24       96778.92      93180.531250\n",
       "25      182901.99     174480.312500\n",
       "26      105008.31     127290.257812\n",
       "27       35673.41      17195.531250\n",
       "28       99937.59      87890.640625\n",
       "29      156122.51     149297.578125\n",
       "30       81005.76      71295.851562\n",
       "31      192261.83     203775.375000\n",
       "32      191792.06     203631.562500"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"Actual Profit\" : y_test.flatten(),\n",
    "    \"Predicted Profit\" : y_pred.flatten(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
